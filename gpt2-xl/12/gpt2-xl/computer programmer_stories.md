Once upon a time, there was a computer programmer named Alan Turing, and one day he discovered a flaw in the fundamental mathematical theory of computers. His discovery prompted an enormous rush towards machines that could handle computations in a humanly meaningful way. If it's possible to be accurate and computationally complete at the same time, how much easier could be something like a human language? In short, what's the bottleneck of artificial intelligence?

Let's imagine a computer that learns from past experience by looking at the world and comparing, for instance, the "pattern" of colors in a rainbow with the "pattern" of colors in other images. It uses these "patterns" to generate images with an accurate depiction of the underlying colors. And then at each step by comparing the real rainbow with the simulated rainbow in a series of steps it is able to generate the real rainbow on each step. After a few steps a new image is generated, where the image matches the simulated one and it is ready to reproduce every image in a series, and so on.

To the human eye this might seem much like a series of sequential images. And yet to the computer it can be just a collection of bits and bytes, a few bits of information. Each bit represents a color. And each byte represents just one color. It is essentially comparing the color on each pixel on the rainbow (it's not the same for every pixel) and is compared with other images in its memory. If there